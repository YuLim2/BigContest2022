{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0aa2b5a",
   "metadata": {},
   "source": [
    "## 제주도 관광 이슈 크롤링\n",
    "네이버 뉴스에서 해당하는 달의 관광 이슈 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5fed983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssl import SSLError\n",
    "from urllib import parse\n",
    "from urllib.error import URLError\n",
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import socket\n",
    "import random\n",
    "import argparse\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae240b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(query, save_as, begin, end, sort=0, field=1, delay=0.5, timeout=30, page_limit=50):\n",
    "    '''\n",
    "    :param query: 네이버 '뉴스'란에서 검색할 검색어\n",
    "    :param save_as: 검색 결과 저장 경로\n",
    "    :param begin: '기간' -> 검색 기간 시작\n",
    "    :param end: '기간' -> 검색 기간 끝\n",
    "    :param sort: '유형' -> 0(관련도순) 1(최신순) 2(오래된순)\n",
    "    :param field: '영역' -> 0(전체) 1(제목)\n",
    "    :param delay: (옵션) 검색 리퀘스트 간격 (초)\n",
    "    :param timeout: (옵션) 타임아웃 시 기다릴 시간 (초)\n",
    "    :param page_limit: (옵션) 검색 결과에서 몇 페이지까지 갈 것인지 결정\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    # prerequisite\n",
    "    df = pd.DataFrame(columns=['link', 'title', 'date', 'article'])\n",
    "\n",
    "    # index settings\n",
    "    # a single pages includes 10 news, starting from page 1 (index 1~10)\n",
    "    current_index = 1\n",
    "    max_index = 2\n",
    "\n",
    "    while (current_index <= max_index) and (1 + current_index // 10 <= page_limit):\n",
    "        print('\\n' + 'crawling... %s (current_page / max_page %i/%i)' % (query, 1 + current_index // 10, 1 + max_index // 10))\n",
    "        url = make_url(query, sort, field, begin, end, current_index)\n",
    "        print('making url', url)\n",
    "\n",
    "        print('making beautifulsoup object from html')\n",
    "        bsobj = make_bsobj(url, delay, timeout, trial=10)\n",
    "\n",
    "        if bsobj is None:\n",
    "            continue\n",
    "        print('extracting naver news urls from bsobj')\n",
    "        naver_news_urls = make_naver_news_urls(bsobj)\n",
    "        print(naver_news_urls)\n",
    "\n",
    "        for url in naver_news_urls:\n",
    "            print('\\topening:', url)\n",
    "            news_bsobj = BeautifulSoup(url, 'html.parser')\n",
    "\n",
    "            if news_bsobj is None:\n",
    "                continue\n",
    "\n",
    "            attributes = get_attributes(news_bsobj)\n",
    "            if attributes is None:\n",
    "                continue\n",
    "\n",
    "            date, article, title, newspaper = attributes\n",
    "            df = df.append({'link': url,\n",
    "                            'title': title,\n",
    "                            'newspaper': newspaper,\n",
    "                            'date': date,\n",
    "                            'article': article}, ignore_index=True)\n",
    "            print('\\t', title)\n",
    "\n",
    "        print('saving updated df')\n",
    "        df = df.sort_values(by=['date'])\n",
    "        df.to_excel(save_as, engine='xlsxwriter')\n",
    "\n",
    "        print('updating current_news_index info')\n",
    "        current_index += 10\n",
    "        max_index = get_max_index(bsobj)\n",
    "        if max_index is None:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2487f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_url(query, sort, field, begin, end, page):\n",
    "    url = \"https://search.naver.com/search.naver?&where=news&query=\" + parse.quote(query)\n",
    "    url += \"&sort=%i\" % sort\n",
    "    url += \"&field=%i\" % field\n",
    "    url += \"&ds=\" + begin + \"&de=\" + end\n",
    "    url += \"&nso=so:r,p:\"\n",
    "    url += \"from\" + begin.replace(\".\", \"\") + \"to\" + end.replace(\".\", \"\")\n",
    "    url += \"&start=\" + str(page)\n",
    "    url += \"&refresh_start=0\"\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efe7e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bsobj(url, delay=0.5, timeout=30, trial=10):\n",
    "    ua = UserAgent(verify_ssl=False)\n",
    "    count = 0\n",
    "\n",
    "    while count < trial:\n",
    "        try:\n",
    "            time.sleep(delay + random.random())\n",
    "            html = urlopen(Request(url=url, headers={'User-Agent': ua.random}), timeout=timeout)\n",
    "            bsobj = BeautifulSoup(html, 'html.parser')\n",
    "            return bsobj\n",
    "        except (URLError, SSLError, socket.timeout) as e:\n",
    "            print('(Error)', e)\n",
    "            print('reloading...')\n",
    "            count += 1\n",
    "            time.sleep(timeout)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62319c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_naver_news_urls(bsobj):\n",
    "    return [link['href'] for link in bsobj.find_all('a', 'news_tit')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faf3c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes(bsobj):\n",
    "    def _get_title(bsobj):\n",
    "        title = bsobj.select('a', 'news_tit')[0].text\n",
    "        title = title.encode('utf-8', 'replace').decode()\n",
    "        print(title)\n",
    "        return title\n",
    "\n",
    "    def _get_article(bsobj):\n",
    "        article = bsobj.select('#articleBodyContents')[0].text\n",
    "        article = article.encode('utf-8', 'replace').decode()\n",
    "        return article\n",
    "\n",
    "    def _get_date(bsobj):\n",
    "        splits = bsobj.select('.t11')[0].text.split(' ')\n",
    "        date = splits[0] + ' ' + splits[2]\n",
    "        date = datetime.datetime.strptime(date, '%Y.%m.%d. %H:%M')\n",
    "        date += datetime.timedelta(hours=12 * int(splits[1] == '오후'))\n",
    "        print(date)\n",
    "        return date\n",
    "\n",
    "    def _get_newspaper(bsobj):\n",
    "        newspaper = bsobj.find(\"div\", class_=\"press_logo\").find('img', alt=True).get('alt')\n",
    "        return newspaper\n",
    "\n",
    "    try:\n",
    "        return _get_date(bsobj), _get_article(bsobj), _get_title(bsobj), _get_newspaper(bsobj)\n",
    "    except IndexError:\n",
    "        print('(Error) crawling failed (maybe url is redirected to somewhere else)')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02de2f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_index(bsobj):\n",
    "    paging = bsobj.find(\"div\", {\"class\": \"sc_page_inner\"})\n",
    "    if not paging:\n",
    "        print('(WARNING!) no results found')\n",
    "        return None\n",
    "\n",
    "    atags = paging.find_all('a')\n",
    "    if not atags:\n",
    "        print('(WARNING!) there is only one page')\n",
    "        return None\n",
    "\n",
    "    return max([int(atag[\"href\"].split('start=')[1]) for atag in atags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ccabadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arguments():\n",
    "    # Argument configuration\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--query', type=str, required=True, help='query to search on NAVER')\n",
    "    parser.add_argument('--begin', type=str, required=True, help='crawling begin point (%%Y.%%m.%%d format)')\n",
    "    parser.add_argument('--end', type=str, required=True, help='crawling end point (%%Y.%%m.%%d format)')\n",
    "    parser.add_argument('--save_as', type=str, default='test2.xlsx', help='excel save path')\n",
    "    parser.add_argument('--sort', type=int, default=0, help='search result sorting: 0(relevant), 1(newest), 2(oldest)')\n",
    "    parser.add_argument('--field', type=int, default=1, help='search field: 0(all), 1(title)')\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eaf7852a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "crawling... 제주도관광 (current_page / max_page 1/1)\n",
      "making url https://search.naver.com/search.naver?&where=news&query=%EC%A0%9C%EC%A3%BC%EB%8F%84%EA%B4%80%EA%B4%91&sort=0&field=1&ds=2015.01.01&de=2015.12.31&nso=so:r,p:from20150101to20151231&start=1&refresh_start=0\n",
      "making beautifulsoup object from html\n",
      "extracting naver news urls from bsobj\n",
      "['http://www.newsis.com/ar_detail/view.html?ar_id=NISX20151229_0010503813&cID=10813&pID=10800', 'http://www.nocutnews.co.kr/news/4524790', 'http://www.headlinejeju.co.kr/?mod=news&act=articleView&idxno=261210', 'http://www.newsis.com/ar_detail/view.html?ar_id=NISX20151228_0010501924&cID=10813&pID=10800', 'http://www.headlinejeju.co.kr/?mod=news&act=articleView&idxno=261324', 'http://news.jtbc.co.kr/html/088/NB11132088.html', 'http://www.ablenews.co.kr/News/NewsContent.aspx?CategoryCode=0039&NewsCode=003920151223090111629787', 'http://www.nocutnews.co.kr/news/4522373', 'http://news.donga.com/3/all/20151221/75487308/1', 'http://www.newsis.com/ar_detail/view.html?ar_id=NISX20151214_0010476891&cID=10813&pID=10800']\n",
      "\topening: http://www.newsis.com/ar_detail/view.html?ar_id=NISX20151229_0010503813&cID=10813&pID=10800\n",
      "(Error) HTTP Error 404: Not Found\n",
      "reloading...\n",
      "(Error) HTTP Error 404: Not Found\n",
      "reloading...\n",
      "(Error) HTTP Error 404: Not Found\n",
      "reloading...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 8\u001b[0m, in \u001b[0;36mmake_bsobj\u001b[0;34m(url, delay, timeout, trial)\u001b[0m\n\u001b[1;32m      7\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(delay \u001b[38;5;241m+\u001b[39m random\u001b[38;5;241m.\u001b[39mrandom())\n\u001b[0;32m----> 8\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUser-Agent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mua\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m bsobj \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/urllib/request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/urllib/request.py:531\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 531\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/urllib/request.py:640\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 640\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    562\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, proto, meth_name) \u001b[38;5;241m+\u001b[39m args\n\u001b[0;32m--> 563\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/urllib/request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 502\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/urllib/request.py:755\u001b[0m, in \u001b[0;36mHTTPRedirectHandler.http_error_302\u001b[0;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[1;32m    753\u001b[0m fp\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/urllib/request.py:531\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 531\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/urllib/request.py:640\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 640\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/urllib/request.py:569\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/urllib/request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 502\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/urllib/request.py:649\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcrawl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m제주도관광\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2015.01.01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2015.12.31\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [14], line 39\u001b[0m, in \u001b[0;36mcrawl\u001b[0;34m(query, save_as, begin, end, sort, field, delay, timeout, page_limit)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m naver_news_urls:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mopening:\u001b[39m\u001b[38;5;124m'\u001b[39m, url)\n\u001b[0;32m---> 39\u001b[0m     news_bsobj \u001b[38;5;241m=\u001b[39m \u001b[43mmake_bsobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m news_bsobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [16], line 15\u001b[0m, in \u001b[0;36mmake_bsobj\u001b[0;34m(url, delay, timeout, trial)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreloading...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m         count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 15\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "crawl('제주도관광', 'test.xlsx', '2015.01.01', '2015.12.31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b4221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
